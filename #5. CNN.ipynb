{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = pickle.load(open('mushroom.p', 'rb'))\n",
    "para = json.loads(open('para.json', 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train accuracy: 0.55 Test accuracy: 0.61\n",
      "Epoch: 1 Train accuracy: 0.55 Test accuracy: 0.7\n",
      "Epoch: 2 Train accuracy: 0.7 Test accuracy: 0.765\n",
      "Epoch: 3 Train accuracy: 0.9 Test accuracy: 0.825\n",
      "Epoch: 4 Train accuracy: 0.95 Test accuracy: 0.805\n",
      "Epoch: 5 Train accuracy: 1.0 Test accuracy: 0.865\n",
      "Epoch: 6 Train accuracy: 1.0 Test accuracy: 0.875\n",
      "Epoch: 7 Train accuracy: 1.0 Test accuracy: 0.9\n",
      "Epoch: 8 Train accuracy: 1.0 Test accuracy: 0.9\n",
      "Epoch: 9 Train accuracy: 1.0 Test accuracy: 0.895\n",
      "Epoch: 10 Train accuracy: 1.0 Test accuracy: 0.9\n",
      "Epoch: 11 Train accuracy: 1.0 Test accuracy: 0.9\n",
      "Epoch: 12 Train accuracy: 1.0 Test accuracy: 0.88\n",
      "Epoch: 13 Train accuracy: 1.0 Test accuracy: 0.9\n",
      "Epoch: 14 Train accuracy: 1.0 Test accuracy: 0.885\n",
      "Epoch: 15 Train accuracy: 0.9 Test accuracy: 0.855\n",
      "Epoch: 16 Train accuracy: 0.95 Test accuracy: 0.88\n",
      "Epoch: 17 Train accuracy: 1.0 Test accuracy: 0.87\n",
      "Epoch: 18 Train accuracy: 1.0 Test accuracy: 0.875\n",
      "Epoch: 19 Train accuracy: 1.0 Test accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "_, w, h, c = data_set['train_image'].shape\n",
    "num_of_class = len(np.unique(data_set['train_label'])) # train_label에 등장하는 class의 개수로 전체 클래스의 개수를 추정\n",
    "log = {\n",
    "    'loss' : [],\n",
    "    'training_accuracy' : [],\n",
    "    'test_accuracy' : []\n",
    "}\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_epochs = 20\n",
    "batch_size = 20\n",
    "\n",
    "l_rate = para['learning_rate']\n",
    "num_of_iteration = para['num_of_iteration']\n",
    "print_frequency = para['print_frequency']\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, w, h, c])\n",
    "y = tf.placeholder(tf.int32, [None, 1])\n",
    "Y_one_hot = tf.one_hot(y, num_of_class)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, num_of_class])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 3, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01)) \n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "L2_flat = tf.reshape(L2, [-1, 8 * 8 * 64]) \n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[8 * 8 * 64, 2], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([2]))\n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    "\n",
    "xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_one_hot)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.equal(tf.argmax(logits, 1), tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "def batch_index(l, batch_size):\n",
    "    a = l // batch_size\n",
    "    b = np.random.permutation(l)\n",
    "    return np.split(b, a)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for ind in batch_index(len(data_set['train_image']), batch_size):\n",
    "            X_batch, y_batch = data_set['train_image'][ind], np.reshape(data_set['train_label'][ind], (-1,1))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        test_y_batch = np.reshape(data_set['test_label'], (-1,1))\n",
    "        acc_test = accuracy.eval(feed_dict={X: data_set['test_image'], y: test_y_batch})\n",
    "        print(\"Epoch:\", epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
